{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a4f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas \"sentence-transformers[train]\" 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273a8816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# 1. Analyze. Understand the dataset better - how can we create a better dataset?\n",
    "# 2. Create test dataset\n",
    "# 3. Use step wise evaluation because epoch takes too much time - unnecessary for early stopping evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c340516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer, losses, \n",
    "    SentenceTransformerTrainer, SentenceTransformerTrainingArguments\n",
    ")\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import TripletEvaluator, EmbeddingSimilarityEvaluator\n",
    "from transformers import EarlyStoppingCallback\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce36b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"model_name\": \"BAAI/bge-m3\",\n",
    "    \"train_file\": \"malayalam_dict.csv\",\n",
    "    \"dev_file\": None,  # Optional; will auto-split from train_file if not set\n",
    "    \"output_path\": f\"./finetuned-bge-m3-{datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n",
    "    \"batch_size\": 16,\n",
    "    \"num_epochs\": 20,\n",
    "    \"max_seq_length\": 256,\n",
    "    \"loss_type\": \"multiple_negatives\",  # \"triplet\" or \"multiple_negatives\"\n",
    "    \"warmup_ratio\": 0.1,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"use_amp\": True,\n",
    "    \"early_stopping_patience\": 3,\n",
    "    \"early_stopping_threshold\": 0.05,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    required_cols = [\"word\", \"definition\", \"incorrect_definition\"]\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing column: {col}\")\n",
    "        df[col] = df[col].fillna(\"\").astype(str).str.strip()\n",
    "\n",
    "    df = df.rename(columns={\"word\": \"anchor\", \"definition\": \"positive\", \"incorrect_definition\":\"negative\"})    \n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_examples(df, loss_type=\"multiple_negatives\"):\n",
    "    examples = []\n",
    "\n",
    "    if loss_type == \"triplet\":\n",
    "        dataset = Dataset.from_pandas(df)\n",
    "        return dataset\n",
    "    if loss_type == \"multiple_negatives\":\n",
    "        dataset = Dataset.from_pandas(df[[\"anchor\", \"positive\"]])\n",
    "        return dataset\n",
    "    raise ValueError(f\"Unsupported loss type: {loss_type}\")\n",
    "\n",
    "\n",
    "def split_train_dev(df, dev_file=None, split_ratio=0.1, min_dev_size=100):\n",
    "    if dev_file and os.path.exists(dev_file):\n",
    "        dev_df = load_data(dev_file)\n",
    "        train_df = df\n",
    "    else:\n",
    "        dev_size = max(int(len(df) * split_ratio), min_dev_size)\n",
    "        dev_df = df.sample(dev_size, random_state=42)\n",
    "        train_df = df.drop(dev_df.index)\n",
    "\n",
    "    return train_df.reset_index(drop=True), dev_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08838fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_evaluator(dev_examples, loss_type):\n",
    "    if loss_type == \"triplet\":\n",
    "        return TripletEvaluator(\n",
    "            anchors=dev_examples[\"anchor\"],\n",
    "            positives=dev_examples[\"positive\"],\n",
    "            negatives=dev_examples[\"negative\"],\n",
    "            name=\"mal-triplet-dev\",\n",
    "        )\n",
    "    else:\n",
    "        return EmbeddingSimilarityEvaluator(\n",
    "            sentences1=dev_examples[\"anchor\"],\n",
    "            sentences2=dev_examples[\"positive\"],\n",
    "            scores=[1.0] * len(dev_examples),\n",
    "            name=\"ml-embeddings-dev\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62044308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    model_name = config[\"model_name\"]\n",
    "    logging.info(f\"Loading model: {model_name}\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "    model.max_seq_length = config[\"max_seq_length\"]\n",
    "\n",
    "    df = load_data(config[\"train_file\"])\n",
    "    train_df, dev_df = split_train_dev(df, config[\"dev_file\"])\n",
    "\n",
    "    logging.info(f\"Training samples: {len(train_df)}, Validation samples: {len(dev_df)}\")\n",
    "\n",
    "    train_examples = prepare_examples(train_df, config[\"loss_type\"])\n",
    "    dev_examples = prepare_examples(dev_df, config[\"loss_type\"])\n",
    "\n",
    "    # train_dataset = input_examples_to_dict(train_examples)\n",
    "    # eval_dataset = input_examples_to_dict(dev_examples)\n",
    "\n",
    "    evaluator = create_evaluator(dev_examples, config[\"loss_type\"])\n",
    "\n",
    "    if config[\"loss_type\"] == \"triplet\":\n",
    "        train_loss = losses.TripletLoss(model)\n",
    "    else:\n",
    "        train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "    training_args = SentenceTransformerTrainingArguments(\n",
    "        output_dir=config[\"output_path\"],\n",
    "        num_train_epochs=config[\"num_epochs\"],\n",
    "        per_device_train_batch_size=config[\"batch_size\"],\n",
    "        per_device_eval_batch_size=config[\"batch_size\"] // 2,\n",
    "        warmup_ratio=config[\"warmup_ratio\"],\n",
    "        learning_rate=config[\"learning_rate\"],\n",
    "        fp16=config[\"use_amp\"],\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        optim=\"adamw_torch_fused\", \n",
    "        batch_sampler=BatchSamplers.NO_DUPLICATES,\n",
    "\n",
    "        logging_steps=100,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "\n",
    "    early_stopper = EarlyStoppingCallback(\n",
    "        early_stopping_patience=config[\"early_stopping_patience\"],\n",
    "        early_stopping_threshold=config[\"early_stopping_threshold\"]\n",
    "    )\n",
    "\n",
    "    trainer = SentenceTransformerTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_examples,\n",
    "        eval_dataset=dev_examples,\n",
    "        loss=train_loss,\n",
    "        evaluator=evaluator,\n",
    "        callbacks=[early_stopper],\n",
    "    )\n",
    "\n",
    "    logging.info(\"Starting training...\")\n",
    "    trainer.train()\n",
    "    logging.info(f\"Training completed. Model saved to: {config['output_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698d579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(CONFIG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lingua",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
