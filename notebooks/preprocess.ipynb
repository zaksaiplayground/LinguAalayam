{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_samam_data():\n",
    "    samam_df = pd.read_csv(\"../data/raw/samam/glossary_df.csv\", sep='\\t')\n",
    "    # Step 1: Split rows using '-' where available\n",
    "    initial_split = samam_df[\"Malayalam\"].str.split('-', n=1, expand=True)\n",
    "    initial_split.columns = ['Word', 'Meaning']\n",
    "\n",
    "    # Step 2: Separate rows that have and don't have a meaning after '-'\n",
    "    rows_with_meaning = initial_split[~initial_split[\"Meaning\"].isna()]\n",
    "    rows_without_meaning = initial_split[initial_split[\"Meaning\"].isna()]\n",
    "\n",
    "    # Step 3: For rows without '-', split using pattern like (1), (2), etc.\n",
    "    def split_by_numbered_pattern(text):\n",
    "        parts = re.split(r'\\s*\\(\\d+\\)\\s*', text, maxsplit=1)\n",
    "        if len(parts) == 2:\n",
    "            return pd.Series([parts[0].strip(), parts[1].strip()])\n",
    "        else:\n",
    "            return pd.Series([text.strip(), \"\"])  # fallback if pattern not found\n",
    "\n",
    "    # Apply pattern-based split\n",
    "    split_rows = rows_without_meaning[\"Word\"].apply(split_by_numbered_pattern)\n",
    "    split_rows.columns = ['Word', 'Meaning']\n",
    "\n",
    "    # Step 4: Combine both sets of parsed rows\n",
    "    combined_df = pd.concat([rows_with_meaning, split_rows], ignore_index=True)\n",
    "\n",
    "    # Step 5: Clean up â€” remove (n) patterns and strip whitespace\n",
    "    samam_cleaned_df = combined_df.applymap(lambda x: re.sub(r'\\(\\d+\\)', '', x).strip())\n",
    "\n",
    "    return samam_cleaned_df\n",
    "\n",
    "def prepare_datuk_data():\n",
    "    datuk = pd.read_csv(\"../data/datuk/files/datuk\", sep='\\t')\n",
    "    datuk = datuk[[\"from_content\", \"to_content\"]].applymap(lambda x: re.sub(r'\\s?\\d+$', '', x).strip())\n",
    "    datuk = datuk.rename(columns={\"from_content\": \"Word\", \"to_content\": \"Meaning\"})\n",
    "    return datuk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samam_cleaned_df = prepare_samam_data()\n",
    "datuk_cleaned_df = prepare_datuk_data()\n",
    "test_data_from_samam = samam_cleaned_df[~samam_cleaned_df['Word'].isin(datuk_cleaned_df['Word'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b09b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_from_samam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lingua",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
